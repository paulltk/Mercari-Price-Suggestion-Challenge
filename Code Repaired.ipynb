{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import statistics\n",
    "import heapq\n",
    "import re, string\n",
    "\n",
    "path = \"C:\\\\Users\\pault\\OneDrive\\Documenten\\GitHub\\input\" # pauls path\n",
    "#path = \"/home/afalbrecht/Documents/Leren en Beslissen/\" #add your path here, dit is een test\n",
    "os.chdir(path)\n",
    "\n",
    "train = pd.read_csv('train.tsv', delimiter='\\t', encoding='utf-8')\n",
    "print(\"train size:\", train.size)\n",
    "\n",
    "test = pd.read_csv('test.tsv', delimiter='\\t', encoding='utf-8')\n",
    "print(\"test size:\", test.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small test space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(train.size)\n",
    "\n",
    "train.get_value(1, \"price\")\n",
    "a = statistics.mean([1, 4, 5, 6, 4, 3, 2])\n",
    "print(a)\n",
    "\n",
    "train.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample = train.loc[0:10]\n",
    "\n",
    "# sorts a column and returns a dictionary with a list of indexes that have the same text/number in that column. \n",
    "def sort_index_by_column(data, column):\n",
    "    dct = {'nan': []}\n",
    "    for index, row in data.iterrows():\n",
    "        if row[column] == row[column]:\n",
    "            if row[column] in dct: \n",
    "                dct[row[column]].append(index)\n",
    "            else: \n",
    "                dct[row[column]] = [index]\n",
    "        else:\n",
    "            dct[\"nan\"].append(index)\n",
    "    return dct\n",
    "\n",
    "#deletes all the keys that have a list with only one value \n",
    "def delete_einzelgangers(dictionary):\n",
    "    new_dict = {}\n",
    "    for key in dictionary:\n",
    "        if len(dictionary[key]) != 1:\n",
    "               new_dict[key] = dictionary[key]\n",
    "    return new_dict\n",
    "\n",
    "# for every list, replace all the indexes with prices\n",
    "def replace_index_with_price(dicti, data):\n",
    "    new_dict = {}\n",
    "    for key in dicti: \n",
    "        lst = []\n",
    "        for ind in dicti[key]: \n",
    "            lst.append(data.get_value(ind, \"price\"))\n",
    "        new_dict[key] = lst\n",
    "    return new_dict\n",
    "\n",
    "# calculates various things for every key\n",
    "def mean_var_amount_per_dict_key(dicti):\n",
    "    mean_dict = {}\n",
    "    for key in dicti: \n",
    "        mean = statistics.mean(dicti[key])\n",
    "        variance = statistics.variance(dicti[key])\n",
    "        amount = len(dicti[key])\n",
    "        mean_dict[key] = [mean, variance, int(amount)]\n",
    "    return mean_dict\n",
    "\n",
    "# gets the amount of times a word is being used in the item description\n",
    "def get_common_words(data):\n",
    "    dct = {}\n",
    "    for index, row in data.iterrows():\n",
    "        for word in row[\"item_description\"].split(\" \"):\n",
    "            if word in dct: \n",
    "                dct[word] += 1\n",
    "            else: \n",
    "                dct[word] = 1\n",
    "    highest_keys = sorted(dct, key=dct.get, reverse=True)\n",
    "    new_dct = {}\n",
    "    for key in highest_keys:\n",
    "        new_dct[key] = dct[key]\n",
    "    return new_dct\n",
    "\n",
    "def hasNumbers(inputString):\n",
    "    return any(char.isdigit() for char in inputString)\n",
    "\n",
    "# every item (except a few NaN's) have three categories. Here we split those in three different columns.\n",
    "def split_categories(data):\n",
    "    data[\"first_cat\"] = \"\"\n",
    "    data[\"second_cat\"] = \"\"\n",
    "    data[\"third_cat\"] = \"\"\n",
    "    for index, row in data.iterrows():\n",
    "        if row[\"category_name\"] == row[\"category_name\"]:\n",
    "            data.set_value(index, \"first_cat\", row[\"category_name\"].split(\"/\")[0])\n",
    "            data.set_value(index, \"second_cat\", row[\"category_name\"].split(\"/\")[1])\n",
    "            data.set_value(index, \"third_cat\", row[\"category_name\"].split(\"/\")[2])\n",
    "        #print(row)\n",
    "    return data\n",
    "\n",
    "# replaces the item description with \n",
    "def change_item_description(data):\n",
    "    for index, row in data.iterrows():\n",
    "        if isinstance(row[\"item_description\"], list) == True:\n",
    "            break\n",
    "        else:\n",
    "            des = row[\"item_description\"]\n",
    "            des = des.lower()\n",
    "            regex = re.compile('[' +re.escape(string.punctuation) + '\\\\r\\\\t\\\\n]')\n",
    "            txt = regex.sub(\" \", des)\n",
    "            stopwords = \"\"\"rm i me my myself we our ours ourselves you your yours yourself yourselves he him \n",
    "            his himself she her hers herself it its itself they them their theirs themselves what which who whom \n",
    "            this that these those am is are was were be been being have has had having do does did doing a an the \n",
    "            and but if or because as until while of at by for with about against between into through during before \n",
    "            after above below to from up down in out on off over under again further then once here there when where \n",
    "            why how all any both each few more most other some such no nor not only own same so than too very s t can \n",
    "            will just don should now\"\"\"\n",
    "            words = [w for w in txt.split(\" \") \\\n",
    "                     if not w in stopwords]\n",
    "            data.set_value(index, \"item_description\", words)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_item_description(sample)\n",
    "split_categories(sample)\n",
    "\n",
    "sample.head(5)\n",
    "\n",
    "def lists_for_vector(data):\n",
    "    cat = []\n",
    "    item_des = []\n",
    "    \n",
    "    for index, row in data.iterrows():\n",
    "        #print(row[\"first_cat\"])\n",
    "        cat.append(row[\"first_cat\"])\n",
    "        cat.append(row[\"second_cat\"])\n",
    "        cat.append(row[\"third_cat\"])\n",
    "        for word in row[\"item_description\"]:\n",
    "            item_des.append(word)\n",
    "    item_des = list(set(item_des))\n",
    "    cat = list(set(cat))\n",
    "    return item_des, cat\n",
    "\n",
    "change_item_description(train)\n",
    "split_categories(train)\n",
    "d, c = lists_for_vector(train)\n",
    "\n",
    "print(len(d))\n",
    "print(len(c))\n",
    "\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sort_brand_name_ind = delete_einzelgangers(sort_index_by_column(sample, \"brand_name\"))\n",
    "# for key in sort_brand_name_ind: \n",
    "#     print(key + \":\", sort_brand_name_ind[key])  \n",
    "\n",
    "sort_brand_name_price = replace_index_with_price(sort_brand_name_ind, sample)\n",
    "# for key in sort_brand_name_price: \n",
    "#     print(key + \":\", sort_brand_name_price[key])\n",
    "    \n",
    "sort_brand_name_mva = mean_var_amount_per_dict_key(sort_brand_name_price)\n",
    "# for key in sort_brand_name_mva:\n",
    "#     print(key + \" - mean:\", int(sort_brand_name_mva[key][0]), \"variance:\", \n",
    "#     int(sort_brand_name_mva[key][1]), \"amount:\", sort_brand_name_mva[key][2])\n",
    "        \n",
    "words = get_common_words(sample)\n",
    "#for word in words: \n",
    "#    print(word + \":\", words[word])\n",
    "\n",
    "# for index, row, in sample.iterrows():\n",
    "#     descr = row[\"item_description\"]\n",
    "#     if hasNumbers(descr) == True: \n",
    "#         print(row[\"name\"], descr, \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "    \n",
    "test_sen = np.array([['een', 'mooie', 'aap'], \n",
    "                     ['een', 'goede', 'aap', ''], \n",
    "                     ['een', 'vette', 'slang'], \n",
    "                     ['een', 'mooie', 'slang', ''], \n",
    "                     ['een', 'grote', 'slang'], \n",
    "                     ['een', 'gave', 'aap', ''], \n",
    "                     ['een', 'mooie', 'koe'], \n",
    "                     ['een', 'lieve', 'koe', ''],\n",
    "                     ['een', 'gave', 'eend'], \n",
    "                     ['een', 'vette', 'eend', ''], \n",
    "                     ['een', 'mooie', 'eend', ''],\n",
    "                     ['een', 'lieve', 'eend', ''],\n",
    "                     ['een', 'leuke', 'kip', ''],\n",
    "                     ['een', 'mooie', 'kip', ''], \n",
    "                     ['een', 'grote', 'kip', ''],\n",
    "                     ['een', 'vette', 'kip'], \n",
    "                     ['een', 'mooie', 'kip', ''],\n",
    "                     ['een', 'lieve', 'gans', ''], \n",
    "                     ['een', 'mooie', 'gans'], \n",
    "                     ['een', 'gave', 'gans'], \n",
    "                     ['een', 'leuke', 'gans'], \n",
    "                     ['een', 'leuke', 'aap', ''], \n",
    "                     ['een', 'slechte', 'aap', ''],\n",
    "                     ['een', 'lelijke', 'aap', ''], \n",
    "                     ['een', 'kutte', 'aap', ''],\n",
    "                     ['een', 'slechte', 'slang', ''], \n",
    "                     ['een', 'kutte', 'slang'], \n",
    "                     ['een', 'kut', 'slang', ''], \n",
    "                     ['een', 'stomme', 'koe', ''],\n",
    "                     ['een', 'kutte', 'koe'],\n",
    "                     ['een', 'fucking', 'koe', ''],\n",
    "                     ['een', 'domme', 'koe', ''], \n",
    "                     ['een', 'slechte', 'koe'], \n",
    "                     ['een', 'stomme', 'eend', ''], \n",
    "                     ['een', 'slechte', 'eend', ''], \n",
    "                     ['een', 'kut', 'eend', ''], \n",
    "                     ['een', 'stomme', 'kip', ''], \n",
    "                     ['een', 'domme', 'kip', ''], \n",
    "                     ['een', 'stomme', 'kut'],\n",
    "                     ['een', 'slechte', 'kip']])\n",
    "\n",
    "print(len(test_sen))\n",
    "\n",
    "test_goodorbad = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ]\n",
    "\n",
    "print(len(test_goodorbad))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
